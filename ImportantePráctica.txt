Solo se puede usar: Laser y camara delantera
Se puede fusionar imágenes de cámara trasera (algo de panorámica)
No se puede usar nubes de puntos

Calibrar con dos muestras, para calcular distancias (distancia 1 metro y distancia 2 metros, con esto podemos extrapolar distancias).

Detectar delante robot a menos de un metro para aprovechar rebufo

LaserScan
Imagen de video

Calcular áreas

roscore
source devel/setup.bash
roslaunch turtlebot_gazebo_multiple create_multi_robot.launch
rostopic list
rostopic info /robot1/commands/velocity
rostopic pub -r 10 /robot1/commands/velocity geometry_msgs/Twist '{linear: {x: 0.1}}'

rosrun send_velocity_commands send_velocity_commands_node


Con OpenCV (Coger el mejor):
- Fast con surf
- Surf con nor
- Surf con surf

1.- Obtener 2 imágenes
2.- Calcular KeyPoints (2 imágenes)
3.- Calcular Descriptores (2A Key Points)
4.- Calcular Correspondencias (Filtrar)
5.- Obtener Homografía
6.- Aplicar transformación + Unir


http://wiki.ros.org/cv_bridge/Tutorials/UsingCvBridgeToConvertBetweenROSImagesAndOpenCVImages



fgomez@dccia.ua.es

rostopic info /robot2/sensors/imu_data te dice el tipo del mensaje
float t = msg->linear_acceleration[0]


sensor imu -> unidad de medida inhercial (acelerometros y giroscopios)
rostopic echo /robot2/sensors/imu_data

float Quaternion::getPitch(){ return atan2(2*(y*z + w*x), w*w - x*x -y*y + z*z)}

float Quaternion::getYaw(){ return asin(-2*(x*z - w*y));

// Esta es en el eje z
// 0 abajo, -1.5 izquierda, 3(-3) arriba, 1.5 derecha
float Quaternion::getRoll(){ atan2(2*(x*y + w*z), w*w + x*x - y*y -z*z);}


ENLACE PANORAMICA
http://ramsrigoutham.com/2012/11/22/panorama-image-stitching-in-opencv/

gazebo/ModelStatesMessage
el imu es la peste y se va a obtener del objeto 3D dentro del simulador, para el mundo real no funciona pero en el simulador si, coordenadas del simulador.
/gazebo/model_states -> tipo: gazebo_msgs::ModelStates{
	name[]
	pose[]
	twist[]
}
Al obtener ese mensaje te dan de todo el mapa, hay que buscar en name nuestro robot y guardarnos el indice de nuestro robot, para acceder al pose y al twist, la pose tiene position y orientation y el twist tiene vel.lineal y vel.articular.
El mapa mide 20x20 Con estos datos podemos rellenar un mapeado ya que es una matriz de mapa y podemos ponr las paredes a 1 por ejemplo y asi ir dibujando el mapa, siguen siendo quaternions de mierda
